{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "import torch\n",
    "from loss import pairwise_similarity, NT_xent\n",
    "from models.resnet import ResNet18,ResNet50\n",
    "from models.projector import Projector\n",
    "import torch.optim as optim\n",
    "from torchlars import LARS\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from attack_lib import FastGradientSignUntargeted,RepresentationAdv\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "#from utils import progress_bar, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_rng_state(torch.get_rng_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch RoCL training')\n",
    "parser.add_argument('--local_rank', type=int, default=0)\n",
    "parser.add_argument('--epoch', type=int, default=1000)\n",
    "args = parser.parse_args()\n",
    "multi_gpu = True\n",
    "ngpu = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = ngpu\n",
    "torch.distributed.init_process_group(\n",
    "    'nccl',\n",
    "    init_method='env://',\n",
    "    world_size=world_size,\n",
    "    rank=args.local_rank,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_sampler , train_loader, test_loader = data_loader.get_loader(local_rank=args.local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Projector(\n",
       "  (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (linear_2): Linear(in_features=2048, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18(num_classes=10, contrastive_learning=True)\n",
    "projector = Projector(expansion=1)\n",
    "model.cuda()\n",
    "projector.cuda()\n",
    "model       = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "model       = torch.nn.parallel.DistributedDataParallel(\n",
    "                model,\n",
    "                device_ids=[args.local_rank],\n",
    "                output_device=args.local_rank,\n",
    "                find_unused_parameters=True,\n",
    ")\n",
    "projector   = torch.nn.parallel.DistributedDataParallel(\n",
    "                projector,\n",
    "                device_ids=[args.local_rank],\n",
    "                output_device=args.local_rank,\n",
    "                find_unused_parameters=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = float(8/255)\n",
    "alpha = float(2/255)\n",
    "max_iters = 7\n",
    "loss_type=\"sim\"\n",
    "regularize_type = 'other'\n",
    "lr = 0.1\n",
    "weight_decay = 1e-6\n",
    "epochs = args.epoch\n",
    "lr_multiplier = 15.0\n",
    "lamda = float(512)\n",
    "random_start = True\n",
    "advtrain_type = \"Rep\" #Rep/None\n",
    "temperature = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " RepAttack = RepresentationAdv(model, projector, epsilon=epsilon, alpha=alpha, min_val=0.0, max_val=1.0, max_iters=max_iters, _type=\"linf\", loss_type=loss_type, regularize = regularize_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = []\n",
    "model_params += model.parameters()\n",
    "model_params += projector.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_optimizer  = optim.SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "optimizer   = LARS(optimizer=base_optimizer, eps=1e-8, trust_coef=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=lr_multiplier, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(model, acc, epoch, optimizer, save_name_add=''):\n",
    "    # Save checkpoint.\n",
    "    print('Saving..')\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'acc': acc,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer_state' : optimizer.state_dict(),\n",
    "        'rng_state': torch.get_rng_state()\n",
    "    }\n",
    "\n",
    "    save_name = './checkpoint/ckpt_'\n",
    "    save_name += save_name_add\n",
    "\n",
    "    if not os.path.isdir('./checkpoint'):\n",
    "        os.mkdir('./checkpoint')\n",
    "    torch.save(state, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    model.train()\n",
    "    projector.train()\n",
    "\n",
    "    train_sampler.set_epoch(epoch)\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    total_loss = 0\n",
    "    reg_simloss = 0\n",
    "    reg_loss = 0\n",
    "\n",
    "    for batch_idx, (ori, inputs_1, inputs_2, label) in enumerate(train_loader):\n",
    "        ori, inputs_1, inputs_2 = ori.cuda(), inputs_1.cuda() ,inputs_2.cuda()\n",
    "\n",
    "        \n",
    "        attack_target = inputs_2\n",
    "\n",
    "        \n",
    "        advinputs, adv_loss = RepAttack.get_loss(original_images=inputs_1, target = attack_target, optimizer=optimizer, weight= lamda, random_start=random_start)\n",
    "        reg_loss    += adv_loss.data\n",
    "\n",
    "        if not (advtrain_type == 'None'):\n",
    "            inputs = torch.cat((inputs_1, inputs_2, advinputs))\n",
    "        else:\n",
    "            inputs = torch.cat((inputs_1, inputs_2))\n",
    "        \n",
    "        outputs = projector(model(inputs))\n",
    "        similarity, gathered_outputs = pairwise_similarity(outputs, temperature=temperature, multi_gpu=multi_gpu, adv_type = advtrain_type) \n",
    "        \n",
    "        simloss  = NT_xent(similarity, advtrain_type)\n",
    "        \n",
    "        if not (advtrain_type=='None'):\n",
    "            loss = simloss + adv_loss\n",
    "        else:\n",
    "            loss = simloss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        total_loss += loss.data\n",
    "        reg_simloss += simloss.data\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "        if (args.local_rank % ngpus_per_node == 0):\n",
    "            if 'Rep' in args.advtrain_type:\n",
    "                progress_bar(batch_idx, len(train_loader),\n",
    "                             'Loss: %.3f | SimLoss: %.3f | Adv: %.2f'\n",
    "                             % (total_loss / (batch_idx + 1), reg_simloss / (batch_idx + 1), reg_loss / (batch_idx + 1)))\n",
    "            else:\n",
    "                progress_bar(batch_idx, len(train_loader),\n",
    "                         'Loss: %.3f | Adv: %.3f'\n",
    "                         % (total_loss/(batch_idx+1), reg_simloss/(batch_idx+1)))\n",
    "        \n",
    "    return (total_loss/batch_idx, reg_simloss/batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, train_loss):\n",
    "    model.eval()\n",
    "    projector.eval()\n",
    "    if args.local_rank % ngpus_per_node == 0:\n",
    "        checkpoint(model, train_loss, epoch, optimizer, save_name_add='_epoch_'+str(epoch))\n",
    "        checkpoint(projector, train_loss, epoch, optimizer, save_name_add=('_projector_epoch_' + str(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchlars\\lars.py:140: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  p.grad.add_(weight_decay, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "Saving..\n",
      "Time taken for 1 epoch 570.3546478748322\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(0, epochs):\n",
    "    train_loss, reg_loss = train(epoch)\n",
    "    test(epoch, train_loss)\n",
    "end_time = time.time()\n",
    "print(\"Time taken for {} epoch {}\".format(epochs, (end_time - start_time) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
